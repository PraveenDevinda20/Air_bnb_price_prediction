{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6b3e69",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6482e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "input_file = \"../data/raw/listings_detailed.csv\"\n",
    "output_file = \"../data/processed/listings_fixed.csv\"\n",
    "\n",
    "rows = []\n",
    "\n",
    "# Step 1: Read raw CSV safely\n",
    "with open(input_file, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        rows.append(row)\n",
    "\n",
    "# Step 2: Detect the correct number of columns (based on header)\n",
    "expected_cols = len(rows[0])\n",
    "print(f\"Expected columns: {expected_cols}\")\n",
    "\n",
    "# Step 3: Fix rows with wrong number of columns\n",
    "fixed_rows = []\n",
    "for i, row in enumerate(rows):\n",
    "    if len(row) != expected_cols:\n",
    "        print(f\"Fixing row {i+1}: had {len(row)} columns\")\n",
    "        if len(row) < expected_cols:\n",
    "            # Pad missing columns\n",
    "            row += [\"\"] * (expected_cols - len(row))\n",
    "        else:\n",
    "            # Merge extra columns into the last one\n",
    "            row = row[:expected_cols-1] + [\",\".join(row[expected_cols-1:])]\n",
    "    fixed_rows.append(row)\n",
    "\n",
    "# Step 4: Save fixed CSV\n",
    "with open(output_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(fixed_rows)\n",
    "\n",
    "# Step 5: Load into pandas\n",
    "data = pd.read_csv(output_file)\n",
    "print(\"DataFrame shape:\", data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32abfe53",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  \n",
    "pd.set_option('display.max_columns', None)\n",
    "data.isna().sum().to_csv(\"../data/processed/missing_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5195aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data.price\n",
    "data['price'] = data['price'].replace('[\\$,]', '', regex = True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2110871",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Q1 = data[\"price\"].quantile(0.25)   \n",
    "Q3 = data[\"price\"].quantile(0.75)   \n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# outliers = data[(data[\"price\"] < lower_bound) | (data[\"price\"] > upper_bound)]\n",
    "data = data[(data['price'] >= lower_bound) & (data['price'] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3a6cbf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# data[\"price_log\"] = np.log1p(data[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a177a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "drop_cols = ['id','listing_url','scrape_id','name','description',\n",
    "             'picture_url','license',\n",
    "             'host_url','host_thumbnail_url','host_picture_url']\n",
    "\n",
    "data = data.drop(columns=drop_cols, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87d6979",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "for col in ['host_response_rate','host_acceptance_rate']:\n",
    "    data[col] = data[col].replace('%','', regex=True).replace('Unknown', 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a0732",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "num_cols = data.select_dtypes(include=['float64','int64']).columns\n",
    "data[num_cols] = data[num_cols].fillna(data[num_cols].median())\n",
    "\n",
    "cat_cols = data.select_dtypes(include='object').columns\n",
    "data[cat_cols] = data[cat_cols].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63325575",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# plt.hist(data[\"price_log\"], bins=50)\n",
    "# plt.title(\"Distribution of Log-Transformed Prices\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609f118",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# plt.boxplot(data[\"price_log\"], vert=False)\n",
    "# plt.title(\"Boxplot of Log-Transformed Prices\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7ed33",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "    # stats.probplot(data[\"price_log\"], dist=\"norm\", plot=plt)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c8c245",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Percentile-based winsorization\n",
    "lower_cap = data[\"price\"].quantile(0.01)\n",
    "upper_cap = data[\"price\"].quantile(0.99)\n",
    "\n",
    "data[\"price_capped\"] = data[\"price\"].clip(lower=lower_cap, upper=upper_cap)\n",
    "data[\"price_log\"] = np.log1p(data[\"price_capped\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14aa876",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(data[\"price_log\"], bins=50)\n",
    "plt.title(\"Distribution of Log-Transformed Prices\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe1832d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "stats.probplot(data[\"price_log\"], dist=\"norm\", plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a2262",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "sns.histplot(data[\"price_log\"], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e784b9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data['host_since'] = pd.to_datetime(data['host_since'], errors='coerce')\n",
    "data['host_days'] = (pd.to_datetime(\"today\") - data['host_since']).dt.days.fillna(0)\n",
    "\n",
    "data['last_review'] = pd.to_datetime(data['last_review'], errors='coerce')\n",
    "data['days_since_last_review'] = (pd.to_datetime(\"today\") - data['last_review']).dt.days.fillna(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db274c3a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(r\"D:\\SLIIT\\Year 3\\Semester 2\\FDM\\Mini Project\\Air_bnb_price_prediction\\data\\processed\\new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc8ce42",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "data['amenities'] = data['amenities'].fillna(\"\")\n",
    "\n",
    "# Count total number of amenities\n",
    "data['amenities_count'] = data['amenities'].apply(lambda x: len(x.split(',')) if isinstance(x, str) else 0)\n",
    "\n",
    "# Find most frequent amenities\n",
    "top_n = 15\n",
    "all_amenities = data['amenities'].str.split(',').explode().str.strip()\n",
    "top_amenities = all_amenities.value_counts().head(top_n).index\n",
    "\n",
    "# Create binary columns for top amenities (safe version)\n",
    "for a in top_amenities:\n",
    "    col_name = 'has_' + a.replace(\" \", \"_\").replace(\"-\", \"_\").replace(\"/\", \"_\").lower()\n",
    "    data[col_name] = data['amenities'].str.contains(a, case=False, regex=False).fillna(False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7320ef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns=['amenities'])\n",
    "data= data.drop(columns=['last_scraped', 'source','host_id'])\n",
    "data = data.drop(columns=['host_name', 'host_about'])\n",
    "data = data.drop(columns=['calendar_last_scraped'])\n",
    "data = data.drop(columns=['bathrooms'])\n",
    "data = data.drop(columns=['calendar_updated', 'last_review'])\n",
    "data = data.dropna(subset=['host_since'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a307793",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "\n",
    "drop_cols = [\n",
    "    # Price-related\n",
    "    'price',\n",
    "    'price_capped',\n",
    "\n",
    "    # Review dates\n",
    "    'first_review',\n",
    "    'last_review',\n",
    "\n",
    "    # Free-text columns\n",
    "    'name',\n",
    "    'summary',\n",
    "    'description',\n",
    "    'neighborhood_overview',\n",
    "    'notes',\n",
    "    'transit',\n",
    "    'access',\n",
    "    'interaction',\n",
    "    'house_rules'\n",
    "]\n",
    "\n",
    "# Drop if exists in the dataset\n",
    "data = data.drop(columns=[c for c in drop_cols if c in data.columns], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc10da8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Outlier handling for minimum_nights and maximum_nights\n",
    "\n",
    "# Cap minimum_nights at 30 (anything above becomes 30)\n",
    "if 'minimum_nights' in data.columns:\n",
    "    data['minimum_nights'] = data['minimum_nights'].clip(upper=30)\n",
    "\n",
    "# Cap maximum_nights at 365 (anything above becomes 365)\n",
    "if 'maximum_nights' in data.columns:\n",
    "    data['maximum_nights'] = data['maximum_nights'].clip(upper=365)\n",
    "\n",
    "# If dataset has related min/max/avg columns, cap them too\n",
    "for col in data.columns:\n",
    "    if 'minimum_nights' in col.lower():\n",
    "        data[col] = data[col].clip(upper=30)\n",
    "    if 'maximum_nights' in col.lower():\n",
    "        data[col] = data[col].clip(upper=365)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
